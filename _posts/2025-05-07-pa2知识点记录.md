---
title: pa2知识点记录
tags:
  - 一生一芯
date: 2025-05-07
---
# 不停计算的机器
程序就是状态机。程序运行的时候，计算机中所有寄存器，memory的值决定了程序当前的状态和以后的状态。寄存器和memory的总容量决定了状态机的总状态数。程序的运行就等效于状态机在各个状态之间来回切换。
cpu运行指令的流程是fetch decode execute update，取出指令，解码，执行，更新pc也就是下一个指令的地址。
在pa2中的模拟器中，拿到一个instruction之后，是这样执行其具体指令的：首先使用union数据结构来解读分割这个instruction的各个部分：
``` C
typedef union {
  struct { uint8_t rs : 2, rt : 2, op : 4; } rtype;
  struct { uint8_t addr : 4      , op : 4; } mtype;
  uint8_t inst;
} inst_t;
```
union的各个元素共同占有同一块空间。所以这8 bits有三种解读的方法：整体当作inst，当作rtype来解读和当作mtype来解读。可以通过inst_t.rtype.rs或inst_t.mtype.addr来获取这8个bits中的某个切片。
不管是mtype还是rtype都是最后四位作为opcode。所以，模拟器通过查看opcode的四位，用switch case语句，不同的4位组合对应不同的命令，然后对addr或rs rt中的数据进行运算，这样就实现了执行机器代码的效果。
# RTFM
[这里](https://cs.stanford.edu/people/eroberts/courses/soco/projects/risc/risccisc/index.html)有一篇关于risc和cisc对比的文章。我的理解是，cisc是更粗粒度的执行指令，更笨重，但是单个指令做很多事，而risc是细粒度的，能带来更多的优化，但是很繁琐复杂。

对于涉及到的big endian和little endian的问题，我个人的理解是：如果你当前的机器是小端的，编译器也知道，会自动将你的代码处理为小端，同时会把变量存储为小端的格式；如果你的机器是大端的也是同理。但是如果直接将小端编译完成的机器码迁移到大端机就会出问题。举个例子，int m=0h1234，在小端机的机器码里变量被存储为3412，大端机里被存储为1234，但是小端机的编译器在解释3412的时候也会按照小端机的标准来，将其解读为1234，所以在同一个类型的机器上不会出问题。

指令本身就是32位，如果immediate也是32位，则：To create larger constants, use a load upper immediate instruction (lui) followed by an add immediate instruction (addi)。将对这个immediate的处理拆成2个指令，分开去处理。

静态指令和动态指令：dynamic next PC和static next PC。
在程序分析领域中, 静态指令是指程序代码中的指令, 动态指令是指程序运行过程中的指令. 例如对于以下指令序列
100: jmp 102
101: add
102: xor
jmp指令的下一条静态指令是add指令, 而下一条动态指令则是xor指令。
由此可以看出动态指令才是真正的下一个指令。

可以查看gcc -E这个flag，作用就是对源文件进行文本替换，这样可以方便我们查看宏和头文件等等展开后的具体信息。

接下来简单记录一下一个指令在nemu中执行的流程：
cpu_exec->execute->exec_once->isa_exec_once
在这个函数里，就2行代码：

s->isa.inst = inst_fetch(&s->snpc, 4);

return decode_exec(s);

在这个函数里完成了fetch decode execute的循环。inst_fetch是取值，具体来说就是先取对应地址处的指令，再根据指令的长度更新snpc静态地址。取完的地址存储在Decode *s的isa.inst里面。之后调用decode exec函数。具体来说，其核心代码是调用INSTPAT这个宏，宏里对每个instr的字符都进行了macro这个宏的处理。公有的mask和key的值根据不断调用的macro宏而发生变化，在最后将当前指令匹配到某一个现有的支持的指令上。确定了指令，还要确定operand，是通过decode_operand这个命令来根据指令的类型将operand提取出来保存在对应的位置，因为有的指令只有imm，rd，有的却有rd rs1 rs2，并且不同指令imm的编码方式也不同，所以需要定义rs1，rs2，不同类型指令imm的提取宏（函数），然后根据指令类型，分别调用对应的宏（函数）即可。提取完后的结果都存储在相应指针里，最后根据指令类型对相应的寄存器值或memory值执行相关的操作，进行更改即可。
执行完指令后，将dnpc赋值给pc。如果不是jump等语句，dnpc=snpc=pc+4，如果是的话，dnpc已经被更改为对应的目标地址。

这里有几个c语言的语法需要注意：
1. 在定义一个macro的时候，在每一行的末尾使用到了\，这是因为：macro的定义默认只在当前行。如果将macro拓展到很多行，需要使用\，可以理解为续行，认为这行没有结束。\一直到最后一行。这样写还有一个特点就是无法加//注释，这样后面的所有都被认为是注释。解决措施是用block comment /* */。
另外的方法就是#define SAFER_MACRO(x) do {  
    statement1;  
    statement2;  
} while(0)，将其套到do while(0)里。在nemu的代码中很多处都是这样。

1. 这里还涉及到了goto+labels的使用。goto finish和下面的finish：打配合，让代码跳转到某个地方。

2. #define是定义宏，但是#undef意思是取消定义。在这个函数里，只有2句语句被正常运行，macro64（0）和Panic，其余都是定义跳转等等。macro64之后马上就取消了定义，意思就是在这之后macro就没法再使用了，会被认为没定义这个macro。


在运行第一个C程序的时候我们要注意，不同的操作系统不同的CPU架构，其上所含的gcc是不同的。比如苹果就是Unix系统加arm架构，windows就是x86架构加windows系统。我们要编译一个测试代码，编译成riscv的指令集运行，则如果调用本机的gcc，会使得编译出来的是arm指令集。这时候需要交叉编译cross compile，
apt-get install g++-riscv64-linux-gnu binutils-riscv64-linux-gnu
g++-riscv64-linux-gnu意思就是riscv64指令集 Linux系统使用的gcc，编译出来的二进制就能直接用了。如果在做nemu的时候选择的是x86指令集架构，则windows机器本机的x86就可以生成可用的机器代码。
如果想使用GNU binutils来查看生成的bin或elf等文件，比如使用objdump和readelf工具，则需要使用交叉编译版本：需要使用相应的交叉编译版本, 如mips-linux-gnu-objdump, riscv64-linux-gnu-readelf等


如果指令没被定义，将会转到inv宏，这个宏里调用了invalid_inst函数，打印输出信息。

接下来开始添加新的指令到nemu中。在查阅手册的时候，有这些知识点：
unprivileged registers意思是运行在所有mode的命令都能access的regs。RISC-V有三种模式，machine mode supervisor mode和user mode，优先级逐层递减。unprivileged registers是运行在user mode都能获取到的寄存器。比如general purpose registers x0-x31.

手册p23有不同指令类型的instruction format,还有下面的immediate格式，图片的意思是对于一个32位的immediate，其各个位的数据都从32位指令的哪里取得。比如在I type immediate里面，前20位都取指令的最后一位的数（sign extend）。

在手册里，只是说了unprivileged regs有32个，第一个是0，并没有说这些寄存器分别用来干什么，这是由机器决定的。对于我们的nemu，执行指令的时候，指令里的寄存器也是以次序为标记的。所以我们需要先明确对于我们的nemu，寄存器和次序的关系：
"$0", "ra", "sp", "gp", "tp", "t0", "t1", "t2",
    "s0", "s1", "a0", "a1", "a2", "a3", "a4", "a5",
    "a6", "a7", "s2", "s3", "s4", "s5", "s6", "s7",
    "s8", "s9", "s10", "s11", "t3", "t4", "t5", "t6"


查看dummy-riscv32-nemu.txt可得这个程序需要用到的指令。注意machine code后面的注释有的是pseudo instruction，咱们只需要实现riscv32里面有的，不需要实现pseudo instruction。需要根据机器码来看这个指令到底在riscv manual里对应的是什么。
- p26页 addi。
- li是个pseudo-instruction，如果imm少于12位则li等效于一个addi。若其大于12位则li等效于lui+addi。这就是上文提到的32位immediate的处理方法。在dummy.c里，li指令其实就是addi，其指令代码为0x0000_0413。
- p28页jal。由于没有定义J type，我们先添加了J-Type这个类型，并为这个类型编写提取操作数的语句。提取操作数需要用到SEXT这个macro，意思是sign extend。jal本身有一个immediate和rd作为参数，其行为是将immediate+当前jal所在地址得到的值赋给PC，同时将PC+4赋给rd寄存器。这里注意，在取值完成后，我们已经将s->snpc变成了pc+4，所以赋值的时候需要让R(rd)=s->pc+4。
- 在dummy-riscv32-nemu.txt里的ret其实是jalr。翻译过来，意思是imm=0 rs1=1的jalr，意思是计算（rs1号寄存器的值的值）+imm，将其lsb赋为0，跳转到这个位置。并将rd寄存器的值赋为jalr地址+4。如果不需要记录返回值，就将rd设为x0。在这里，ret的机器码翻译过来，就是rd=0，imm=0，rs1=1，也就是跳转到ra这个寄存器里的地址处。ra的这个值恰恰是前面jal放进去的，所以这个语句是ret。
- sb和sw的区别：两者的格式都是sw rs2 imm(rs1)和sb rs2 imm(rs1)。地址的计算方法是相通的，rs1寄存器的值加imm。存储的东西不同，sw是存储整个rs2的32位数，而sb是只存储rs2 32位中的lsb。
- mv的意思是将一个reg的内容复制到另一个reg，是pseudo instruction，实现的时候用addi，将imm=0来实现。j是直接跳转，是pseudo instruction，实现的时候用jal，rd=\*0来实现。




summary: 已经支持并经过测试的指令有
- auipc
- addi
- jal
- lui
- sb
- sh
- sw
- lw
- lb
- lh
- lhu
- lbu
- jalr
- beq
- bne 
- blt 
- bge 
- bltu
- bgeu
- add
- sub
- slti
- sltiu
- slt
- sltu
- add
- or
- xor
- addi
- ori
- xori
- srai
- srli
- slli
- sll
- srl
- sra
- div
- divu
- mul
- rem
- remu
- mulh



接下来我完成了lw sw和lui。我打算测试一下。查阅资料得：auipc的意思是AUIPC (add upper immediate to pc) is used to build pc-relative addresses and uses the U-type format. AUIPC forms a 32-bit offset from the U-immediate, filling in the lowest 12 bits with zeros, adds this offset to the address of the AUIPC instruction, then places the result in register rd. 将auipc指令所在的地址和一个常数相加，将结果赋值给 destination register。


关于地址的部分，可以参考pa1知识点记录的init_isa()标题。
pmem在memory/paddr.c里面已经定义好，是个size为CONFIG_MSIZE的，类型为uint8_t的array。目前里面什么都没有。
在读取指令的时候，调用的是include/cpu/ifetch.h这个文件里定义的inst_fetch这个函数，是专门从memory读取命令的函数。里面调用的vaddr_ifetch这个函数，调用了paddr_read这个函数，里面调用了pmem_read。在这之前，所有的地方的argument对应的地址都是guest memory，类似于0x8000 0004这样的。在pmem_read里，首先调用了guest_to_host这个函数。这个函数接受一个guest memory，返回一个host memory。比如接受0x8000 0004，返回对应的本机上pmem对应元素的地址。这才真正完成了地址转换，之后调用host_read函数读取地址对应的元素。这个函数很简单，有一点值得一提的是，在传入参数的时候，由于不清楚你要读取的长度是多少，函数先让addr为void \*类型，接着有一个case语句，根据情况的不同赋给addr不同类型的指针。当addr的类型被处理好了，只需要return \*addr就可以读取对应长度的数据了。在return的后面跟着的是不同长度的数据，但是我们统一要word_t大小的数据，所以又做了个implicit type casting，这个时候默认从位数少的到位数多的默认是zero extend。我修改了一下这个函数，因为如果按照原始的样子，不管从内存读的是多长的数，都只能是zero extend。我多加了2个len的case，分别为-1和-2.对应生成SEXT的版本，这样就变成了sign extend。
这里引用一下函数的本体语句：
``` C
static inline word_t host_read(void *addr, int len) {
  switch (len) {
    case 1: return *(uint8_t  *)addr;
    case 2: return *(uint16_t *)addr;
    case 4: return *(uint32_t *)addr;
    IFDEF(CONFIG_ISA64, case 8: return *(uint64_t *)addr);
    case -1:
    return SEXT(*(uint8_t *)addr, 8);
    case -2:
    return SEXT(*(uint16_t *)addr, 16);
    default: MUXDEF(CONFIG_RT_CHECK, assert(0), return 0);
  }
}
```
所以，经过了层层包装，pmem_read最终接受guest memory和读取的字节长度len作为输入，返回guest memory处长度为len的数据。地址转换已经被抽象到底层无需care了。


这里可以多体会一下多层抽象的思想，如果换成我写，大概率就是用一个大函数叫read_mem，里面包含了所有的边界判断，更新pc等等操作。这里使用了多层抽象多层封装调用，每一层都有各自的目的。inst_ifetch是专门用来读取指令的函数，显然它除了读取以外还要先更新pc为pc+4。它调用的vaddr_ifetch除了调用paddr_read别的什么都没做，但是这是为了和取数据的函数进行区分。
``` C

word_t vaddr_ifetch(vaddr_t addr, int len) {
  return paddr_read(addr, len);
}

word_t vaddr_read(vaddr_t addr, int len) {
  return paddr_read(addr, len);
}
```
两个函数都是什么也没做只是调用了一个函数。所以理论上这两个函数都可以直接替换为paddr_read，但是为了区分应用场景，一个paddr_read是为了读取指令，另一个paddr_read是为了读取数据。可见为了让人读的舒服加了多少层抽象。在paddr_read里面，除了读内存，还做了边界判断，以免读的内存超过了内存的范围，在pmem_read内部，才是真正做了地址转换+读写内存的操作。所以可以看到，除了核心操作以外，每多做一件事情，就多套一层函数，方便管理。
这种思想还有很多，在nemu里，很多函数在多个文件里用不同的macro来表示，都只是为了在当前的文件里能以更readable的形式呈现出来。

经过复杂的测试，终于支持了dummy文件里的所有指令。运行之后的结果是good trap。

dummy经过测试之后，我尝试继续运行别的测试文件，在add里面涉及到了beq，我决定接下来实现beq bne blt bge bltu和bgeu。在尝试实现这些的时候，遇到了如下的问题：首先在所有的B类语句中都涉及到immediate。在这里首先我们要对immediate进行sign extend，之后由于branch语句要既能往前跳，也能往后跳，所以对于sign extend得到的结果应该以sword_t解读他。sword_t解读就是将其看成2's complement实现的数，有正负。但是在修改之后仍然出错，经过debug发现在immB里的移位逻辑出现错误。移位的位数一定考虑好当前抽取出的位数，再去看移多少位。以上2个bug修改完毕，add文件就能运行完成并且返回good trap了。

这里涉及到了一个新的需要考虑的地方就是我们在INSTPAT_MATCH这个宏里，src1和src2都是word_t类型的。说明在所有的指令的执行语句中都把src1和src2看成了unsigned去执行的。但是目前为止操作不涉及到比较，只有加法，load store，或者是对所含数据的直接操作，符号并不影响。在blt和bltu这两个的对比里就涉及到了这个差别。符号数和无符号数的比较不能一概而论。
我的一开始的想法是在INSTPAT_MATCH里多声明2个变量，这样的缺点就是在每个指令执行的时候都会多这2个变量，绝大多数情况根本用不上。后来的优化是在需要转化为 signed的语句的操作里在对应word_t类型的变量前面做type casting，即(sword_t)src1，这样就实现了局部的引用。

有个语法点可以学一下：在switch case里，如果case的是简单的数字，则非常不直观。解决方法是先创建一个enum变量，里面存储了case的东西，再case对应的enum entry即可。比如
``` C
enum
{
  TYPE_I,
  TYPE_U,
  TYPE_S,
  TYPE_N,
  TYPE_J,
  TYPE_B,
  TYPE_R // none
};
```
这样，case(TYPE_I)等就能直接看出这是I type instruction对应的语句。

接下来接着看下一个文件，add-longlong，这里涉及到了and xor or。注意，不管是在RISCV32指令集里还是在nemu里，and的操作都是&，即bitwise operator，而不是logical operator。

下一个文件 bit，里面涉及到srai，shift right arithmetic immediate。shift right分为2类，logical和arithmetic。前者将移出来的更高位设为0，后者将更高位用原数的符号位填充。在C语言里,>>这个运算符，当使用在signed上时进行arithmetic shift，当使用在unsigned shift时进行logical shift。所以在实现的时候，需要用type casting转变为sword_t。同时，slli srai srli三者虽然属于I类型，但是其改变了I类型原本的12位imm编码方式，用前7位作为opcode，imm只有五位，所以需要重新多一个type for 这种编码方式。同时在bit里还完成了lh sh等。

接下来完成了bubble-sort，crc32

RISCV32有M-extension，是对原本的RISCV32指令集的一个拓展。这里面是关于乘除法的一些指令。包括mul,mulh,mulhu,mulhsu,div,divu,rem,remu。注意没有mulu，原因涉及到了二进制乘法的一个特点：
32位乘32位，结果有可能大于32位。如果只取低32位的话，不管是当signed看还是unsigned看结果都一样。具体来说，在计算机内部，不管是unsigned还是signed都是当作一堆二进制来看的。二进制的乘法操作是不变的，所以不管你怎么解读operand和result，最终得到的结果都是一样的。而mult命令本身就是将结果的低32位赋给rd寄存器，所以不管做的是什么乘法，低32位对应的二进制都是一样的。但是高32位就不同了。事实上假如32位a和32位b相乘，结果是35位，则将结果解读为signed或unsigned差别就在于第36位再高的位置。如果是signed就会自动变成sign extend否则就是0 extend。所以，如果只想取最低位，mul就可以。如果想取高32位就分成了mulh和mulhu。
实现mulh的时候，也要注意，要想如果直接word_t乘word_t，得到的结果也是word_t，32位。如果要想获得高64位，必须先将operand转化为64位，变成(int64_t)(sword_t)src1，将得到的结果 >> 32，再转变为32位的word_t就可以了。从64位转变为32位默认取低32位。

在实现div的时候，需要排查几个特殊的情况：首先，如果除以0，会将-1当作结果赋值给结果寄存器。其次，由于用补码来描述一个数，负数的范围比正数大一。所以如果用最小的负数除以-1，得到的正数是无法正常表示的，这种情况下会返回INT32_MIN。

上面记录的已经实现的代码有可能有遗漏，但是到目前为止，除了讲义提到的hello-str和string2个程序以外，其余程序均已经过了正确的测试，结果是hit good trap。

讲义中提到了分支延迟槽delay slot，这是MIPS32中提到的一种和流水线配合提高效率的方法。具体来说，现代处理器全部是流水线，同时有很多个指令一起在运行。在顺序执行的情况下，直接接着读下一个，接着流水线就行。但是如果有分支语句，其后的指令到底是哪个就要看分支的判断结果。但是如果等待分支结果出来再读取，就会导致一整个周期空白，这叫bubble。现代处理器会使用分支预测的方法提前填充指令。delay slot也是个减少bubble的方法。具体来说，他会有一个检查范围，当有分支语句的时候，会在检查范围里查找指令，which 不受到顺序和其他指令结果的影响，不依赖其余的命令。这样的指令在哪里执行都可以，并且一定会执行。所以就将这样的指令放在branch语句后面。
100: beq 200
101: add
102: xor
...
200: sub
201: j   102
202: slt

若beq指令的执行结果为跳转, 则相应的动态指令流为100 -> 101 -> 200; 若beq指令的执行结果为不跳转, 则相应的动态指令流为100 -> 101 -> 102; 而对于j指令, 相应的动态指令流为201 -> 202 -> 102.
# 程序，运行时环境与AM
程序的运行需要运行时系统的支持。运行时系统，又叫runtime system，是每个编程语言都具有的一个帮助程序正常运行的系统。在nemu里，最简单的运行时系统做的事情就是：只要把程序放在正确的内存位置, 然后让PC指向第一条指令, 计算机就会自动执行这个程序, 永不停止，知道提供了结束的语句。更复杂的情况包括stack heap的管理，IO的管理等等。
运行时环境的一种普遍的存在方式: 库. 通过库, 运行程序所需要的公共要素被抽象成API, 不同的架构只需要实现这些API, 也就相当于实现了支撑程序运行的运行时环境, 这提升了程序开发的效率: 需要的时候只要调用这些API, 就能使用运行时环境提供的相应功能。
更具体的，这些API代表了程序运行对于计算机的需求。因为计算机的cpu架构不同，所以不同的架构对于同一个API的实现方法也不同。但是，每个架构只需要维护好API的具体实现方法，不同的程序需要这个需求，就调用这个API即可。所有的需求的汇总，也就是API的汇总，在这里被称为抽象计算机abstract machine。
AM可以分为这些个部分：
AM = TRM + IOE + CTE + VME + MPE
TRM(Turing Machine) - 图灵机, 最简单的运行时环境, 为程序提供基本的计算能力，其实就是我们已经实现的nemu，除了把程序放在对应地址和调整pc指针以外别的也啥都没干。
IOE(I/O Extension) - 输入输出扩展, 为程序提供输出输入的能力
CTE(Context Extension) - 上下文扩展, 为程序提供上下文管理的能力
VME(Virtual Memory Extension) - 虚存扩展, 为程序提供虚存管理的能力
MPE(Multi-Processor Extension) - 多处理器扩展, 为程序提供多处理器通信的能力 (MPE超出了ICS课程的范围, 在PA中不会涉及).

所以，nemu本质上其实是硬件层面。本来我们可以用硬件来写一个处理指令的电路，在这里把所有的硬件，包括memory，加法器乘法器等等全部用软件写出来。所以nemu处于最底层的。而上层的abstract-machine其实是硬件和软件的中间层。写出了软件代码，通过abstract- machine进行编译，转换成底层nemu能执行的代码，再递交给nemu执行。

volatile关键字，用于可能会在程序外突然改变的变量上：
``` C
volatile int sensor_reading;

int main() {
    // The compiler won't optimize access to sensor_reading
    while (sensor_reading < 100) {
        // Keep waiting
    }
    printf("Sensor reading reached: %d\n", sensor_reading);
    return 0;
}
```
这段程序为例，sensor_reading前面有volatile。如果没有volatile，编译器在编译的时候，每次循环都是判断sensor_reading，编译器知道语句之间没有直接改变该变量的代码，所以编译器就会在下次循环使用上次的数值，所以这就是个永远循环。如果有volatile关键字，compiler每次判断，都从内存里重新读取而不是想当然的做optimization。
这个关键字适用于外接设备IO等等情况，在代码里不会变化，由外界的变化而变化的情况。


inline assembly，内联汇编，是一种在C语言中运行汇编语言的方法，格式如下：
``` C
asm [volatile] ("assembly instructions"
               : output operands
               : input operands
               : clobbered registers);
               
```

这里加volatile是因为我们就是想让程序执行这个语句，编译器不要自作主张删除或者更改。不加的话就无法确定程序的样子是什么样的。
汇编语言的指令需要指定输入寄存器和输出寄存器。在这里的output operands和input operands就是用来指定输入输出的变量和存放的寄存器之间的关系。
比如
``` C
int add_numbers(int a, int b) {
    int result;
    asm("add %0, %1, %2"    // Assembly instruction
        : "=r"(result)      // Output: result goes into any register (=r)
        : "r"(a), "r"(b)    // Inputs: a and b from any registers
        );
    return result;
}
```
汇编指令是add。
The constraint characters (like "r", "=r", etc.) tell the compiler how to handle variables. Here are the most common ones:

"r": Any general-purpose register
"=r": Output to any general-purpose register
"m": Memory location
"i": Immediate constant
"g": Any register, memory, or immediate constant

前面的0%等都是placeholder占位符。所以这段代码的意思就是输入取的值是a和b，这个值来自于你的C程序。汇编语言要想使用值先要存储在寄存器里，这里的"r"意思就是输入a和b存储在任何一个可用的寄存器都可以。输出的"=r"意思也是同理，不过是给输出用的。(result)意思是将输出的值赋给result这个C语言变量。最后一个clobbered registers意思是汇编语言要使用到的寄存器。如果没有这个关键字，compiler可能将结果overwrite到这些寄存器上，使得本来要用到的数据丢失了。clobbered regs可能还会包含memory这个关键字。当汇编语言要往内存里读或写的时候，就要有memory这个关键字。

最safe的写法是将所有hard code的寄存器全部列出来，且一旦有可能涉及到内存读写就写上memory。
下面给出一个例子：

``` C
void memory_clobber_example(void) {
    int array[10] = {1, 2, 3, 4, 5, 6, 7, 8, 9, 10};
    int sum = 0;
    
    // This assembly code sums array elements
    asm volatile(
        "li     t0, 0          \n\t"  // counter = 0
        "li     t1, 0          \n\t"  // sum = 0
        "li     t2, 10         \n\t"  // limit = 10
        "1:                    \n\t"  // loop start
        "bge    t0, t2, 2f     \n\t"  // if counter >= 10, exit
        "slli   t3, t0, 2      \n\t"  // t3 = counter * 4 (word offset)
        "add    t3, %1, t3     \n\t"  // t3 = base + offset
        "lw     t4, 0(t3)      \n\t"  // load array[counter]
        "add    t1, t1, t4     \n\t"  // sum += array[counter]
        "addi   t0, t0, 1      \n\t"  // counter++
        "j      1b             \n\t"  // loop back
        "2:                    \n\t"  // loop end
        "mv     %0, t1"               // store sum to output
        
        : "=r"(sum)
        : "r"(array)
        : "t0", "t1", "t2", "t3", "t4", "memory"
        //                           ^^^^^^^^
        // This tells the compiler that we might read/write
        // any memory location. Without this, the compiler
        // might optimize away array initialization or
        // assume array values haven't changed!
    );
    
    printf("Sum: %d\n", sum);
}
```


## RTFSC
下面对abstract-machine的makefile进行解读。这个abstract-machine的代码写的精妙绝伦，take-away有：
1. 将ifeq(xxx,)用作判断语句
2. error，findstring，wildcard，info，notdir，basename，flavor等等关键字directive的使用
3. 在makefile中不仅能够使用makefile自己定义的variable，还能使用写在.zshrc等环境配置文件中的环境变量。在这里，AM_HOME就是写好的环境变量。两种变量的使用方法是相同的，都是$(variable)。
``` makefile
ifeq ($(MAKECMDGOALS),)
  MAKECMDGOALS  = image
  .DEFAULT_GOAL = image
endif
```
ifeq比较的是2个参数是否相等，参数之间用逗号分隔。MAKECMDGOALS是makefile自带的变量，意思是在通过命令行调用makefile的时候传入的参数。$意思是expand变量。所以第一行的意思是如果make后面没有跟着额外的参数target。
接下来的2句意思是，如果没有额外变量，就让额外变量=image。同时，让image这个target成为没有变量的情况下第一个运行的target。
When you run make without specifying a target, GNU Make normally builds the first target defined in the Makefile that doesn't look like a prerequisite (essentially the first "non-special" target it encounters). By setting .DEFAULT_GOAL, you override this behavior to explicitly declare which target should be built by default.

``` makefile
### Override checks when `make clean/clean-all/html`
ifeq ($(findstring $(MAKECMDGOALS),clean|clean-all|html),)

### Print build info message
$(info # Building $(NAME)-$(MAKECMDGOALS) [$(ARCH)])

### Check: environment variable `$AM_HOME` looks sane
ifeq ($(wildcard $(AM_HOME)/am/include/am.h),)
  $(error $$AM_HOME must be an AbstractMachine repo)
endif

### Check: environment variable `$ARCH` must be in the supported list
ARCHS = $(basename $(notdir $(shell ls $(AM_HOME)/scripts/*.mk)))
ifeq ($(filter $(ARCHS), $(ARCH)), )
  $(error Expected $$ARCH in {$(ARCHS)}, Got "$(ARCH)")
endif

### Extract instruction set architecture (`ISA`) and platform from `$ARCH`. Example: `ARCH=x86_64-qemu -> ISA=x86_64; PLATFORM=qemu`
ARCH_SPLIT = $(subst -, ,$(ARCH))
ISA        = $(word 1,$(ARCH_SPLIT))
PLATFORM   = $(word 2,$(ARCH_SPLIT))

### Check if there is something to build
ifeq ($(flavor SRCS), undefined)
  $(error Nothing to build)
endif

### Checks end here
endif
```

第一行是检验输入的参数里有没有制定的字符串。其中$(findstring find,text)是为了寻找find里面有无text。在这里是寻找输入里有没有clean clean-all和html。没有的话进入下面。

wildcard的用法是$(wildcard pattern)。有2个作用：
The wildcard function serves two primary purposes:

File Existence Checking: It returns the filename if the file exists, or an empty string if it doesn't
Pattern Expansion: It expands shell-like wildcards (e.g., *.c) into a space-separated list of matching filenames

在这里，就是第一个作用，检测$(AM_HOME)/am/include/am.h存不存在。am.h里面保存了abstract machine的API，从最简单的TRM开始一直到最复杂的runtime system的支持，都有封装好的API。没有这个文件，就说明这不是个abstract machine的文件夹。

$(notdir names...)的意思是去除掉names参数的路径，只保留文件名。一般都向上文一样和shell ls配合。basename也是类似作用，它去除的是所有文件名的后缀，比如test.c变成test。这一小段的作用就是提取出support的ARCHS，并且看变量ARCH的值在不在ARCHS里面。不在就输出错误信息。在abstract machine/scripts下面有一堆makefile，每个makefile都针对于一个特定的系统和特定的指令集。从这些makefile名字中提取出支持的，并和当前你要使用的ARCH进行比较。

接下来把ISA和PLATFORM提取出来，作为makefile的2个变量。

当前项目有destination directory。是abstract-machine/build/，每个架构和系统都有一个单独的文件夹。比如对于riscv32-nemu这个文件夹里，存放的是源文件SRCS编译成的.o文件。

接着，将所有要link的文件都聚合起来。这个语句的效果是：如果SRCS是main.c，utils/helper.c，则最终就是在build文件夹下有一个关于架构和平台的文件夹，里面存着对应的.o文件。即build/riscv32-nemu/main.o build/riscv32-nemu/utils/helper.o

接下来定义了LIBS变量。使用的是immediate assignment，因为LIBS变量的定义里包含了LIBS本身，所以如果使用简单的=赋值会导致endless loop。

linkage指的是在所有的库文件夹下的静态链接库文件。比如am和klib是2个库。我们把运行时环境分为2部分，一部分是架构有关的，architecture dependent，还有一部分是架构无关的，architecture independent。am存放有关的，klib存放无关的。在以这两个库的名字命名的文件夹下都有个build文件夹，在build文件夹下存储着am-riscv32-nemu.a和klib-riscv32-nemu.a两个文件。这里可以提一嘴.a文件是静态链接库的格式。动态链接库的格式是.so文件。

flavor返回的是变量的定义类型。如果SRCS没有被定义，则输出nothing to build. 

INCPATH和INCFLAGS的作用是添加include文件，并将其修改为带有-I前缀的，用在编译时候的argument。

CFLAGS声明了一些在编译的时候用到的flags。首先将INCFLAGS包括进去，其次有一些error warning optimization上的优化，再其次传入了一些macro。
``` makfile
CFLAGS   += -O2 -MMD -Wall -Werror $(INCFLAGS) \
            -D__ISA__=\"$(ISA)\" -D__ISA_$(shell echo $(ISA) | tr a-z A-Z)__ \
            -D__ARCH__=$(ARCH) -D__ARCH_$(shell echo $(ARCH) | tr a-z A-Z | tr - _) \
            -D__PLATFORM__=$(PLATFORM) -D__PLATFORM_$(shell echo $(PLATFORM) | tr a-z A-Z | tr - _) \
            -DARCH_H=\"$(ARCH_H)\" \
            -fno-asynchronous-unwind-tables -fno-builtin -fno-stack-protector \
            -Wno-main -U_FORTIFY_SOURCE -fvisibility=hidden
```
-02是optimization level，- MMD是generate dependency files automatically。-Wall和-Werror的作用是让所有的warning都变成error，且激发所有的warning。下面的-D作用是引入macro。具体来说引入的包括ISA ARCH PLATFORM ARCH_H等等。在下面是一些编译上的琐碎事情。

在CFLAGS下面还有C++ flags，assembly flags和 linker flags。

在scripts下面有一堆makefile，每个makefile都适用于一个专门的architecture和system。以riscv32-nemu.mk为例，在这个文件里面还引用了2个makefile，一个是关于riscv32的，一个是关于nemu的，分别在相应的isa文件夹下和platform文件夹下。在riscv.mk下，定义了cross compile的具体形式，并且根据isa的独特性，添加了几个CFLAGS ASFLAGS等等一些flags。在nemu.mk里，定义了一些平台相关的flags。同时，abstract-machine和nemu的交互就是通过这个mk里面定义的target完成的。具体看如下的关键代码：
``` makefile
run: insert-arg
	$(MAKE) -C $(NEMU_HOME) ISA=$(ISA) run ARGS="$(NEMUFLAGS)" IMG=$(IMAGE).bin

gdb: insert-arg
	$(MAKE) -C $(NEMU_HOME) ISA=$(ISA) gdb ARGS="$(NEMUFLAGS)" IMG=$(IMAGE).bin
```
run这个target依赖于insert-arg这个target，这个target再依赖于image这个target。在image里面，做的事情大概是将elf文件转化为bin文件。在有操作系统的处理时，可执行文件是elf，但是在nemu里，我们接受的可执行文件的输入是bin文件。elf文件是给操作系统的loader用的。所以elf文件里含有许多的metadata和header information，再加上actual machine code。但是bin文件只有raw machine code。对于nemu这种没有操作系统的情况下，必须将文件转化为bin格式才能运行，bin里面全是二进制代码。
run里有个-C，意思是切换directory，切换到NEMU_HOME的对应文件夹下，之后运行run。就相当于在NEMU_HOME下运行make run。后面的ISA和ARGS和IMG都是变量定义，IMG就是要传入的bin文件，我们先运行了image这个target，之后将得到的二进制文件赋给IMG这个变量。gdb也是同理，类似于在NEMU_HOME里运行run gdb。

在主makefile和nemu.mk里面都有许多的target。接下来列出make run运行的流程。当type make run的时候，run->insert-arg->image->image-dep->LIBS+image.elf。其中image.elf->\$(LINKAGE) \$(LDSCRIPTS)，后者是link的操作指南，前者包括了所有库文件编译后打包成archive .a文件和所有的.c文件经过编译后生成的.o文件。所以到这里又用到了各个.c .cpp .S等的依赖。
综合下来，abstract-machine做的事情就是，先编译所有的源文件。其中库的代码编译后打包成.a文件，源代码编译后变为object file。之后由linker来链接这两者，链接完后生成了ELF可执行文件。之后通过提取将多余信息去掉，变成纯纯二进制文件，交给nemu来run或gdb。

在nemu的parse_args函数里，对运行nemu的时候传入的参数进行了处理。其中提到了batch mode通过b这个argument来指明。所以我们可以make run的时候就传入-b，这样直接进入batch mode，省的进入后再按c才能运行。如果想要在abstract-machine里面做出更改以便让nemu运行batch mode，则直接更改NEMUARGS即可，这个变量之后就被传入了nemu的make命令里：ARGS="$(NEMUFLAGS)"。

这里再额外说下nemu里的parse_arg函数：
``` C
static int parse_args(int argc, char *argv[])
{
  const struct option table[] = {
      {"batch", no_argument, NULL, 'b'},
      {"log", required_argument, NULL, 'l'},
      {"diff", required_argument, NULL, 'd'},
      {"port", required_argument, NULL, 'p'},
      {"help", no_argument, NULL, 'h'},
      {0, 0, NULL, 0},
  };
  int o;
  while ((o = getopt_long(argc, argv, "-bhl:d:p:", table, NULL)) != -1)
  {
    switch (o)
    {case 1:
      img_file = optarg;
      return 0;
    ...

  }
  return 0;
}
```
while循环里的"-bhl:d:p:"中的"-"的作用是不仅处理optional argument，对于non optional argument也接受。如果没有这个的话，只会接受-开头的参数，比如-b和-l。但是有这个的话，如果接下来的argument不以-开头，会让o=1，并将optarg赋为这个argument。所以在这里，就是让img_file=optarg了。这就是为什么在nemu makefile里
``` makefile
NEMU_EXEC := $(BINARY) $(ARGS) $(IMG)

run-env: $(BINARY) $(DIFF_REF_SO)

run: run-env
	$(call git_commit, "run NEMU")
	$(NEMU_EXEC)
```
binary是可执行文件，列举在这里的意思就是直接执行，后面的ARGS和IMG全部当成参数。IMG就是non optional argument。所以可以得出，为了让nemu运行某个bin文件，除了更改源代码里的img，还可以make run后面传入参数。


进入到pa的下一个阶段，我实现了部分字符串处理函数，让string运行成功。接着我实现了sprintf。在实现的时候，我注意到，sprintf的format string可以有很多花样。可以明确声明参数的位置，可以将本来需要在format string里声明的width precision等等让他们接受后面的参数。但是为了方便，我们只实现了format specifier。我们使用了stdarg.h这个库，这个库是专门用来处理不固定数量参数的函数的情况。实现完后，hello-str测试成功。


所以到目前为止，我们的小计算机可以支持运行不调用库的简单的程序，包括对于寄存器数值的操作，对于memory的简单操作，可以支持对于string.c和sprintf函数的调用，因为相关的代码已经被实现，在编译的时候会被编译成正确的机器代码。

计算机的层层抽象：
概念相同的一个硬件模块有着不同的实现方式, 比如处理器既可以通过NEMU中简单的解释方式来实现, 也可以通过类似QEMU中高性能的二进制翻译方式来实现, 甚至可以通过verilog等硬件描述语言来实现一个真实的处理器.
ISA是硬件向软件提供的可以操作硬件的接口。不管底层是什么，上层程序只需要将指令放在对应的位置，下层“硬件”就可以执行指令。上层不用管下层到底是真正的电路还是software模拟出来的硬件。所以说，AM的API对不同ISA(如x86/mips32/riscv32)的接口进行了抽象, 为上层的程序屏蔽ISA相关的细节
运行时环境可以通过对AM的API进行进一步的封装, 向程序提供更方便的功能。

目前我们虽然能运行程序，但是还不够完备。heap stack等内容都没实现，将在下面的阶段进一步完善。
# 基础设施2
下面给出代码框架的[图片](https://ooo.0x0.ooo/2025/05/16/OdNPGM.jpg)。
## 将指令输出的代码到底在哪里？
通过RTFSC可以得到，decode这个struct最后有个member variable叫logbuf，是个char array。在exec_once这个函数执行的时候，前半部分是执行指令，执行完后会将当前执行的机器码和通过调用反汇编功能得到的汇编代码一起输入进logbuf，在exec_once函数返回的时候，传入的decode \*s的logbuf已经准备好了。execute函数除了调用n次exec_once函数以外，还调用了n次trace_and_difftest()函数。正是在trace_and_difftest()里面，logwrite函数将logbuf里面的内容写到了文件，也就是nemu-log.txt里面。

结论：在execute函数的n次循环内部的trace_and_difftest()函数里。

## 如何确保在出错的时候能输出？
经过检查，在程序出错的时候，并没有对nemu_state进行更改，只是assert(0)强行终止运行了。但是在execute里，执行了n次循环，每次循环却都要查看nemu_state.state的值是否符合条件。所以我们先对程序出错的时候的处理代码进行一些更改，不让assert来结束，而是通过更改nemu_state来结束。
### 对各个state的分析
nemu_state的定义在/home/yubocui/ysyx-workbench/nemu/include/utils.h里。
``` C
enum { NEMU_RUNNING, NEMU_STOP, NEMU_END, NEMU_ABORT, NEMU_QUIT };

typedef struct {
  int state;
  vaddr_t halt_pc;
  uint32_t halt_ret;
} NEMUState;
```
NEMU_QUIT专用于q退出的情况，NEMU_RUNNING就是正常运行的情况。NEMU_ABORT被用来指示出错导致程序直接abort的情况，NEMU_END意思是程序执行完毕，执行到末尾了。
### 我的更改
我在内存读取的检测出错的函数out_of_bound里面，加了一个if nemu_state.state=NEMU_RUNNING, nemu_state.state=NEMU_ABORT;的语句。目前已知代码唯一出错停止运行的地方就是存取内存越界的时候，所以这样代码一出错，首先将状态设为了abort。
### 更改之后的效果
在cpu_exec函数的一开始和结束的时候，都会检测状态。一开始的检测是为了卡住END ABORT和QUIT三种情况。结束的检测是让running变成stop，其余情况下保留原始的状态。如果在程序上一次运行的时候出现了bug，会将状态调整为nemu_abort，则下次运行无法进入。如果程序运行的时候监视点被hit了，则状态为nemu_stop，这是因为下文会提到的execute的设置。

而在execute()的内部，n次循环每次的末尾都会检测nemu_state。一旦发现不是RUNNING就会马上break跳出循环，随即跳出函数。当watchpoint发生更改的时候，会让nemu_state变成nemu_stop，进而停止执行。所以要想在代码运行的时候出错，马上跳出循环终止运行，只需要在对应的指令执行的时候调整nemu_state为abort即可。

从上面的框架也可以看出，即使execute传入的参数是n且内部for循环理论上循环n次，在遇到特殊情况下也会提前退出。这是因为每次循环末尾都会检查状态是否是 running。比如在watchpoint hit，memory read/write error和程序运行到了最后一个指令的这三种情况下，状态不再是running所以就提前跳出循环。不是running，就可能是stop abort和end三种情况。其中，abort和end无法再次进入cpu exec这个函数，只有stop可以再次进入，也就是说只有watchpoint hit的情况下能在此接着运行，这也符合我们的预期。
我们的目标是在出错的时候输出相关的错误信息，所以要对abort这个state进行识别。
## 输出相关实现
首先我们实现了iringbuf的相关API，包括
int iringbuf_init(void)
int iringbuf_append(char logbuf\[128])
void iringbuf_log(void)

在execute函数的循环之前，调用iringbuf_init函数，之后在trace_and_difftest里面进行append和log的判断。

在实现的时候，有个bug属于经典错误，需要注意：不管是lessthanmax函数还是morethanmax函数，都涉及到新malloc一块内存。不管什么时候新malloc内存，都要手动进行初始化。因为malloc的内存不确保里面存的是什么内容，不进行初始化直接进行操作会有错误。

注意，出于simplicity的考虑，我们的iringbuf只包括了出错命令前面的命令。


## mtrace实现
mtrace的实现，按照讲义，需要先阅读Kconfig等代码，看一下itrace是怎么开启的。
这里引用一下pa1里关于配置程序的讲义内容：
``` markdown
在一个有一定规模的项目中, 可配置选项的数量可能会非常多, 而且配置选项之间可能会存在关联, 比如打开配置选项A之后, 配置选项B就必须是某个值. 直接让开发者去管理这些配置选项是很容易出错的, 比如修改选项A之后, 可能会忘记修改和选项A有关联的选项B. 配置系统的出现则是为了解决这个问题.

NEMU中的配置系统位于nemu/tools/kconfig, 它来源于GNU/Linux项目中的kconfig, 我们进行了少量简化. kconfig定义了一套简单的语言, 开发者可以使用这套语言来编写"配置描述文件". 在"配置描述文件"中, 开发者可以描述:

配置选项的属性, 包括类型, 默认值等
不同配置选项之间的关系
配置选项的层次关系
在NEMU项目中, "配置描述文件"的文件名都为Kconfig, 如nemu/Kconfig. 当你键入make menuconfig的时候, 背后其实发生了如下事件:

检查nemu/tools/kconfig/build/mconf程序是否存在, 若不存在, 则编译并生成mconf
检查nemu/tools/kconfig/build/conf程序是否存在, 若不存在, 则编译并生成conf
运行命令mconf nemu/Kconfig, 此时mconf将会解析nemu/Kconfig中的描述, 以菜单树的形式展示各种配置选项, 供开发者进行选择。所以当你输入make menuconfig的时候，生成的节目是参考nemu/Kconfig来完成渲染的。
退出菜单时, mconf会把开发者选择的结果记录到nemu/.config文件中
运行命令conf --syncconfig nemu/Kconfig, 此时conf将会解析nemu/Kconfig中的描述, 并读取选择结果nemu/.config, 结合两者来生成如下文件:
可以被包含到C代码中的宏定义(nemu/include/generated/autoconf.h), 这些宏的名称都是形如CONFIG_xxx的形式
可以被包含到Makefile中的变量定义(nemu/include/config/auto.conf)
可以被包含到Makefile中的, 和"配置描述文件"相关的依赖规则(nemu/include/config/auto.conf.cmd), 为了阅读代码, 我们可以不必关心它
通过时间戳来维护配置选项变化的目录树nemu/include/config/, 它会配合另一个工具nemu/tools/fixdep来使用, 用于在更新配置选项后节省不必要的文件编译, 为了阅读代码, 我们可以不必关心它
所以, 目前我们只需要关心配置系统生成的如下文件:

nemu/include/generated/autoconf.h, 阅读C代码时使用
nemu/include/config/auto.conf, 阅读Makefile时使用

```

经过阅读源代码可得，在Kconfig的第139行开始定义了TRACE_START TRACE_END ITRACE和TRACE_COND四个宏。这四个宏都是depends on TRACE的。TRACE在前面是个可选择的项。所以如果在Kconfig里面选择了TRACE，下面的四个就都有了。按照ITRACE的定义添加了MTRACE并将printf的操作套在了CONFIG_MTRACE宏内部。
## ftrace实现
### ELF
在这里先记录一下学习ELF的笔记。我们首先需要用readelf程序来读取一个elf文件，得到的内容可以供我们解读
#### ELF header
```
ELF Header:
  Magic:   7f 45 4c 46 01 01 01 00 00 00 00 00 00 00 00 00 
  Class:                             ELF32
  Data:                              2‘s complement, little endian
  Version:                           1 (current)
  OS/ABI:                            UNIX - System V
  ABI Version:                       0
  Type:                              EXEC (Executable file)
  Machine:                           Intel 80386
  Version:                           0x1
  Entry point address:               0x8048280
  Start of program headers:          52 (bytes into file)
  Start of section headers:          14892 (bytes into file)
  Flags:                             0x0
  Size of this header:               52 (bytes)
  Size of program headers:           32 (bytes)
  Number of program headers:         9
  Size of section headers:           40 (bytes)
  Number of section headers:         31
  Section header string table index: 28
```
- Magic：前四个字符是7f 45（E） 4c（L） 46（F），表示这是个ELF文件。
- class：记录这是32 bit还是64 bit
- data：记录是little endian还是big endian
- version：就是个1
- OS/ABI：不同的操作系统有不同的application binary interface ABI，这个域专门说明了当前使用的是哪个系统和哪套ABI(ABI就是操作系统和executable code之间的接口)。这个域和下一个ABI version能一起来确定用的是哪套。
- machine：指明这是什么架构，amd还是arm还是什么。
- type：所有的ELF文件分为3类，executable，relocatable和shared object file。这个域指明这是哪个文件。

从这里能得到ELF文件的数据分布。一进入文件就是 ELF header，之后是 program header，之后是data，最后是section header。
#### file data
除了上面提到的ELF header，ELF文件还包含三部分：program headers/segments，section headers/sections，data。
解读ELF有2个视角：一个是for linker使用的，是segments视角，另一个视角可以给数据和指令分类，是sections视角。
##### program headers
program header的作用：An ELF file consists of zero or more segments, and describe how to create a process/memory image for runtime execution. When the kernel sees these segments, it uses them to map them into virtual address space, using the mmap(2) system call. In other words, it converts predefined instructions into a memory image. If your ELF file is a normal binary, it requires these program headers. Otherwise, it simply won’t run.
ELF文件会给出program headers开始的地址，一共有几个program headers，每个headers的type offset  virtual address和physical address
有几个值得注意的type：
- GNU_EH_FRAME：存储的是exception handlers
- GNU_STACK：存储的是stack information
##### section headers
记录了各个sections的信息。在各个section中，重要的主要有4个sections：.text, .data, .rodata, .bss
- .text: 存储的是executable code
- .data：initialized data with read/write access rights
- .rodata: initialized data, with read access rights only
- .bss: uninitialized data, with read/write access rights
除了这些，下文要提到的.symtab和.strtab也属于sections，都可以在section header里看到。
##### symbol table
symbol table是一个section within an ELF file。在ELF的section header中可以找到这个section：.symtab
A symbol table is essentially a directory or index of all the "symbols" in a program, where a symbol is a named entity like a function, variable, or constant. Think of it as a lookup table that maps names (like "printf" or "main") to their actual locations in memory.
因为计算机操作的对象是地址而不是变量和函数的名字，而在程序里存储的是名字，所以symbol table存在的意义就是将变量名和地址对应起来。symbol table是compiler在编译的时候产生的。
一般程序里有2个symbol table，分别是.symtab和.dynsym，前者是symbol table，后者是dynamic symbol。
这里要先说一下allocable ELF sections和non-allocable ELF sections的区别。在ELF文件里，有些 section是be needed at runtime，这些sections叫allocable；有些是被linker debugger需要的，叫non-allocable。一个程序需要先经过编译链接等等，再被load进memory执行。所以load的时候只load那些runtime needed的就行，那些被linker debugger所需要的在运行时用不上，节省memory就不load。
完整的full symbol table，也就是symtab，既包括了runtime needed的，也包括了link debug needed的。而dynsym是symtab的子集，只包含了allocable的部分。

从readelf的输出信息来看，symbol table里面的name的数据类型是string。但readelf输出的信息是已经经过解析的, 实际上符号表中Name 属性存放的是字符串在字符串表(string table)中的偏移量.string其实并不是直接存储在symbol table里的，而是单独存储在一个string table里，symbol table里只记录其在string table里的位置。

画个图显示string table和symbol table的关系是这样的：
```
Section Headers:
  [Nr] Name              Type            Addr     Off    Size   ES Flg Lk Inf Al
  [ 7] .strtab           STRTAB          00000000 001408 00009b 00      0   0  1
                                                  |
                                   +--------------+
                        ++         V
00001400                |V         00 61 64 64 2e 63 00 74  | ........add.c.t|
00001410  72 6d 2e 63 00|6d 61 69  6e 61 72 67 73 00 5f 74  |rm.c.mainargs._t|
00001420  72 6d 5f 69 6e|69 74 00                    ^      |rm_init._stack_p|
                        |                            |
                        |                            +----------------+
                        |                                             |
                        +-----------------------------------------+   |
Symbol table '.symtab' contains 10 entries:                       |   |
   Num:    Value  Size Type    Bind   Vis      Ndx Name           |   |
     7: 00000000     0 FILE    LOCAL  DEFAULT  ABS 7 (trm.c)      |   |
     8: 80000108     1 OBJECT  LOCAL  DEFAULT    2 13(mainargs) --+   |
     9: 800000e8    32 FUNC    GLOBAL DEFAULT    1 22(_trm_init) -----+
```
可以看到string table做的事情就是在对应的地址位置将symbol table的各个symbol的名字拼接在了一起而已。

symbol table里面存储的是程序需要用到的global variable，function等等。注意macro definition和local variable并没有包含进去。macro definition是在编译器编译的时候就进行了替换，没等到程序运行的时候就已经不见了。而local variable是存放在stack上的。只有公共的，可执行文件随时有可能需要的，比如function call或global variables的值，才会放在symbol table里面。

以下是一个symbol table的例子：
```
Symbol table '.symtab' contains 28 entries:
   Num:    Value  Size Type    Bind   Vis      Ndx Name
     0: 00000000     0 NOTYPE  LOCAL  DEFAULT  UND
     1: 80000000     0 SECTION LOCAL  DEFAULT    1
     2: 80000108     0 SECTION LOCAL  DEFAULT    2
     3: 8000010c     0 SECTION LOCAL  DEFAULT    3
     4: 8000020c     0 SECTION LOCAL  DEFAULT    4
     5: 00000000     0 SECTION LOCAL  DEFAULT    5
     6: 00000000     0 FILE    LOCAL  DEFAULT  ABS add.c
     7: 00000000     0 FILE    LOCAL  DEFAULT  ABS trm.c
     8: 80000108     1 OBJECT  LOCAL  DEFAULT    2 mainargs
     9: 800000e8    32 FUNC    GLOBAL DEFAULT    1 _trm_init
    10: 80009000     0 NOTYPE  GLOBAL DEFAULT    4 _stack_pointer
    11: 80000108     0 NOTYPE  GLOBAL DEFAULT    1 _etext
    12: 80000000     0 NOTYPE  GLOBAL DEFAULT  ABS _pmem_start
    13: 8000022c     0 NOTYPE  GLOBAL DEFAULT    4 _bss_start
    14: 80000109     0 NOTYPE  GLOBAL DEFAULT    2 edata
    15: 80009000     0 NOTYPE  GLOBAL DEFAULT    4 _heap_start
    16: 80001000     0 NOTYPE  GLOBAL DEFAULT    4 _stack_top
    17: 80009000     0 NOTYPE  GLOBAL DEFAULT    4 end
    18: 80000010    24 FUNC    GLOBAL DEFAULT    1 check
    19: 80000108     0 NOTYPE  GLOBAL DEFAULT    1 etext
    20: 80000000     0 FUNC    GLOBAL DEFAULT    1 _start
    21: 00000000     0 NOTYPE  GLOBAL DEFAULT  ABS _entry_offset
    22: 80000028   180 FUNC    GLOBAL DEFAULT    1 main
    23: 80000109     0 NOTYPE  GLOBAL DEFAULT    2 _data
    24: 8000010c   256 OBJECT  GLOBAL DEFAULT    3 ans
    25: 80009000     0 NOTYPE  GLOBAL DEFAULT    4 _end
    26: 800000dc    12 FUNC    GLOBAL DEFAULT    1 halt
    27: 8000020c    32 OBJECT  GLOBAL DEFAULT    4 test_data
```
type是func的对应的name就和add.c里面定义的函数是一样的，所以说symbol table建立了函数名和其地址之间的映射关系。symbol table里面 FUNC对应的size就是函数的大小，代码范围。所以如果想检验运行了哪个函数，只需要看当前的代码是否在[value, value+size]里面。

### 具体实现路径
先记录几个bug：
在vscode里面，#include <elf.h>的时候，出现了“检测到 #include 错误。请更新 includePath”的错误。查阅网上，有如下的解决方法：https://zhuanlan.zhihu.com/p/616798432
解决好后，仍然没有。查阅资料可得mac中没有原生的elf.h文件。如这个帖子：https://ixx.life/notes/cross-compile-linux-on-macos/
elf.h多用于交叉编译。我首先将文件加到了对应的include path里，经过编译后，编译没有问题。但是运行的时候也是运行不了。Mac下的所有可执行文件都不是ELF文件格式，所以无法测试。

接下来说具体的实现方法：
我们用了elf.h这个头文件。具体可以通过man 5 elf来查询相关信息。elf.h里面有很多数据结构，是专门用来interpret ELF file的。里面有很多数据结构。头部数据结构有Ehdr（ELF header）Phdr（program header）Shdr（section header）。将对应数量的byte读入到对应的数据结构里，就可以调用对应数据结构里面的宏定义和member function。

下面具体介绍：
ElfN_Addr       Unsigned program address, uintN_t
           ElfN_Off        Unsigned file offset, uintN_t
           ElfN_Section    Unsigned section index, uint16_t
           ElfN_Versym     Unsigned version symbol information, uint16_t
           Elf_Byte        unsigned char
           ElfN_Half       uint16_t
           ElfN_Sword      int32_t
           ElfN_Word       uint32_t
           ElfN_Sxword     int64_t
           ElfN_Xword      uint64_t

这记录了主要的数据类型。

对于Ehdr来说，是这样定义的：
``` C
typedef struct {
               unsigned char e_ident[EI_NIDENT];
               uint16_t      e_type;
               uint16_t      e_machine;
               uint32_t      e_version;
               ElfN_Addr     e_entry;
               ElfN_Off      e_phoff;
               ElfN_Off      e_shoff;
               uint32_t      e_flags;
               uint16_t      e_ehsize;
               uint16_t      e_phentsize;
               uint16_t      e_phnum;
               uint16_t      e_shentsize;
               uint16_t      e_shnum;
               uint16_t      e_shstrndx;
           } ElfN_Ehdr;
```
只要往一个Ehdr的指针写入sizeof(Ehdr)大小的byte，就可以使用这些宏定义。具体的含义可以在manual page查阅。
重要的member variable有：e_phentsize e_shentsize e_phnum e_shnum e_shstrndx。
我们要想获取到symbol table里FUNC的size和value域，首先需要先找到symbol table，则先要找到section header table。而section header table offset由e_shoff给出。从文件开始跨越这个offset就到了shoff。
先将指定的数据字节数读入section header table对应的数据结构里（这个数据结构是一个array of Shdr）。每个Shdr里面都有name。我们的想法是从这个name来挑选是symtab的一项。但是symbol table里面的name并不是字符串，没法直接比较。name正如上文所说，是按照section header string table index来存储的。所以我们得先获取到section header string table。由于特殊性，这个string table的API可以直接获取到，即e_shstrndx。我们在比较symtab里面元素的name的时候，得先根据name field里面的index获取到其字符串类型的名字。这需要同时找到名为strtab的section header table entry。（这里涉及到一个知识点，就是string table有好几个。section header的各个entry的name由一个string table来存储，而symbol table的name由另一个string table来存储，dynamic symbol table的name也有一个新的string table来存储。我们先获取到section header string table，再从中找到symbol string table，并从这个symbol string table里面寻找）
具体来说，获取的关键语句示例有：
``` C
// ELF header(map_base is the start of the file)
ehdr = (Elf64_Ehdr *)map_base;
// section header
// ehdr->e_shoff means section header offset. map_base+ehdr->e_shoff means the start of the section header. 
shdr = (Elf64_Shdr *)((char *)map_base + ehdr->e_shoff);
// string table
// ehdr->e_shstrndx means the index of string table in the section header. 
// shdr[ehdr->e_shstrndx] means the specific string table entry in the section header. 
// sh_offset is a field of shdr, which means the offset of given section from the start
char *section_strtab = (char *)map_base + shdr[ehdr->e_shstrndx].sh_offset;
// compare section header name
// sh_name is the index, offset. so in every iteration, every different i, section_name points to the string
char *section_name = section_strtab + shdr[i].sh_name;
// we need to find strtab and symtab
// if st_info=STT_FUNC, this is a function. 
if (ELF64_ST_TYPE(symtab[i].st_info) == STT_FUNC) {
            char *name = strtab + symtab[i].st_name;
          }
```

我们首先更改parse_arg函数，额外多出一个命令行选项，接受参数并赋值给ftrace_file。注意既然在monitor.c里面添加了init_ftrace函数，就要添加相关的声明。之后在这个文件里添加了一个init_ftrace函数。这个函数做的事情就是将输入的ELF文件的信息提取，并输出所有symbol table里type是FUNC的entry。

初步写完函数后，接下来要对函数进行测试。我尝试更改了native.mk这个makefile，多加了一个ftrace_test的target。以后可以通过调整monitor里面的img file和native.mk里面的文件，实现运行一个二进制，并解读该二进制的 ELF文件。

遇到的bug：在读取文件的时候，fopen打开文件有不同的选项。w意思是write，而r是读取。rb意思是read binary。要想解读ELF文件，需要用rb这个option而不是write。如果用write，会导致源文件直接被清空。

测试完成，可以正确输出所有的FUNC的名字，说明程序的读取是没问题的。接下来要做的事情就是：在Kconfig中添加相关选项，将有关的函数套到选项里面。选择合适的地方放置ftrace_finish函数和ftrace函数。
一开始的想法是将函数的关闭和free内存等等全部移动到finish函数里，后来发现需要声明的东西过多。于是更改为在init函数里读取出所有的func和他们的value和size，跨文件只传递读取出来的值即可。读取出来存储在内存里就马上关闭文件。

我们定义了一个struct叫func_info，这个struct存储了所有函数的name value和size信息。我们声明了一个array，里面全是func_info，这个array就存储了当前程序的所有func的信息。由于是global struct，在其余文件里也能获得。我们通过其global的特点，通过指针，在init里面更改他，并在别的文件使用它。

我们将ftrace的相关代码放在trace_and_difftest里面，每次运行一个指令，都会再运行一次trace_and_difftest函数。在这个函数里面，ftrace通过将当前的pc和各个函数的范围[value,value+size)进行比较。如果当前pc所在的函数和前一个指令所在的函数不同，就说明新进入了一个函数，于是就return再call。至于在讲义里提到的jal和jalr的判断。由于我们是将pc和范围做对比，不管你怎么跳，跳进了范围就会判断出函数的调用，跳出了范围就是返回了函数。由于在symbol table里函数都是不重叠的，不会出现函数里套函数的情况，所以我认为这种情况可以判断充分。

gprintstep也是和MAX_INST_TO_PRINT相比。是否因为最大值是10 就无法打印了？
## 冗余的符号表
简单来说，一个C语言源代码程序，需要先被编译生成object file，是以o为后缀；再和其他的object file一起被链接起来。在gcc相关命令中，-c这个flag的作用就是只编译不链接。-o意思是重新取个名字而不使用默认的名字。
object file和最终生成的ELF executable里面都有symbol table。strip -s命令可以去掉这两个文件中的symbol table section。如果去掉了 ELF里面的symbol table，其仍然可以正常运行。但是去掉object file里面的symbol table，接着用其生成ELF文件，是无法正常运行的。原因如下：
在ELF文件里，除了symbol table，还有一个section叫dynamic symbol table，前面也提到过。在运行executable的时候，执行的操作是dynamic linking，这个阶段使用的是dynamic symbol table而不是symbol table。所以strip掉symbol table不影响最终的运行，他可以提供debug information。但是在object file里面的symbol table扮演的不是这个角色。要想了解其作用，需要对linking的过程有更深入的了解：linking的本质上是各个object文件的symbol table的对照。每个object file的symbol table告诉别人，我这个文件提供哪些symbol。在linking的时候，编译器会查看当前文件需要哪些别的object文件里的symbol，并在其余的文件里进行寻找。这个时候如果去掉了某个object文件的symbol，别的文件就不知道这个文件还提供什么symbol，导致别的文件找不到自己要用的symbol，所以就会报错。
## trace与性能优化
这里引用一下讲义里的话，拓展知识面。
我们让大家在NEMU实现trace工具, 是作为一种基础设施来帮助大家进行调试. 事实上, trace除了可以帮助大家认识程序如何运行之外, 还可以指导开发者进行程序和系统的优化, 例如:

可以基于ftrace进一步分析出调用memcpy()时的参数情况, 比如dest和src是否对齐, 拷贝的内存长度是长还是短, 然后根据频繁出现的组合对memcpy()的算法实现进行优化
可以基于ftrace统计函数调用的次数, 对访问次数较多的函数进行优化, 可以显著提升程序的性能
可以基于itrace过滤出分支跳转指令的执行情况, 作为分支预测器(现代处理器中的一个提升性能的部件)的输入, 来调整分支预测器的实现, 从而提升处理器的性能
可以基于mtrace得到程序的访存序列, 作为缓存(现代处理器中的另一个提升性能的部件)模型的输入, 对预取算法和替换算法的优化进行指导(你将会在Lab4中体会这一点)
trace对性能优化来说如此重要, 是因为trace反映了程序运行的真实行为, 如果你拍脑袋优化了程序中一个只会调用1次的函数, 可以想象这样的优化对程序总体性能几乎没有任何提升. 而trace其实向我们展示了程序运行过程中的细节事件, 如果我们对这些事件进行统计意义上的分析, 我们就可以知道哪些事件才是频繁发生的, 而优化这些频繁发生的事件, 才能从统计意义上提升程序和系统的性能, 这才是性能优化的科学方法.
## AM作为基础设施
到目前为止，我们已经实现的是：自己写了一个SoC。这个SoC包括内存，寄存器等元素。这个SoC是RISCV32架构的，可以实现RISCV32的相关机器指令。这是硬件的部分。软件的部分包括源代码和库代码klib文件夹。源代码指的是C文件。但是C文件还会调用库函数，这些函数都在klib文件夹里。函数用C代码写的，也是我们自己实现的。我们借助交叉编译的方法将所有的C代码编译成riscv32架构的机器代码并运行在我们自己写的SoC上。

软件(klib)和硬件(NEMU)都是你编写的, 它们的正确性都是不能100%保证的. 大家在中学的时候都学习过控制变量法: 如果能把其中一方换成是认为正确的实现, 就可以单独测试另一方的正确性了! 比如我们在真机上对klib进行测试, 如果测试没通过, 那就说明是klib的问题, 因为我们可以相信真机的硬件实现永远是对的; 相反, 如果测试通过了, 那就说明klib没有问题, 而是NEMU有bug.

一个新的问题是, 我们真的可以很容易地把软件移植到其它硬件上进行测试吗? 聪明的你应该想起来AM的核心思想了: 通过一组抽象的API把程序和架构解耦. AM的思想保证了运行在AM之上的代码(包括klib)都是架构无关的, 这恰恰增加了代码的可移植性. 想象一下, 如果string.c的代码中有一条只能在NEMU中执行的nemu_trap指令, 那么它就无法在真机上运行.

在abstract-machine里面，除了riscv32等架构以外，还有个叫native的架构。它的作用是使用最普通的gcc编译文件，因为调用的是本机的gcc，所以编译出的代码是本机上能运行的。所以就是将程序编译在本机上运行。这样可以测试软件的错误。软件没错，再移植到NEMU上运行。

我们在am-kernels/tests/cpu-tests/下执行命令：
``` sh
make ALL=string ARCH=native run
```
其中的ALL就是要编译的C文件名，ARCH就是编译的目标架构。我们可以将ARCH定为native，在native上测试我们的软件代码。通过观察string.c等的代码可以得到，他们include的文件里面包含了他们要用到的memcmp等函数，最终都导向了我们自己写的abstract-machine/am/src里面的文件。所以如果string.c在native上运行正确，说明我们的软件部分，也就是库函数是正确的。

这到底是怎么实现的呢？查看makefile可以得到，在am-kernels/tests/cpu-tests/下的makefile里面显示，如果运行的时候没有加ALL，则cpu-tests里的所有文件都被执行。如果加了ALL=xxx，则只执行对应的文件。执行的时候，会根据对应的文件名生成一个makefile叫Makefile.xxx，这里面有三行代码，其中一行调用了另一个makefile，在另一个makefile里面记录着编译的具体选项。执行对应的文件，在这里就是执行文件生成的makefile，which 会将文件编译根据你给出的ARCH。编译好后经过判断，如果文件正确就返回PASS否则返回FAIL。

在makefile里，是这样写的：
``` makefile
@if make -s -f $@ ARCH=$(ARCH) $(MAKECMDGOALS); then \
		printf "[%14s] $(COLOR_GREEN)PASS$(COLOR_NONE)\n" $* >> $(RESULT); \
	else \
		printf "[%14s] $(COLOR_RED)***FAIL***$(COLOR_NONE)\n" $* >> $(RESULT); \
	fi
```
首先这是个条件判断语句，结构是if then else fi（if的终止）。这是个shell command语句。这个语句必须是一行，没有换行符，所以用\来连接。在shell script里，if后面的语句运行没有错误就返回0，这时if视为条件满足。所以和C语言中的if判断条件不同。

### 2个makefile的解读
当我们在/home/yubocui/ysyx-workbench/am-kernels/tests/cpu-tests/下运行make命令的时候，调用的是该路径下的makefile。具体看这个makefile，可以看到在每个ALL变量对应的值，都会产生一个临时的makefile专门用来运行这个变量对应的文件。比如string就会产生一个文件Makefile.string。